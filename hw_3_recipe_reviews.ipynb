# # 0. Импорт необходимых библиотек
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.neighbors import KNeighborsClassifier
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)


# ---
# # 1. Описание задачи и загрузка данных

# **Цель:** Решить задачу **мультиклассовой классификации** — предсказать оценку (рейтинг) рецепта (`stars` от 0 до 5) на основе характеристик отзыва и самого рецепта.
# **Целевая переменная:** `stars` (переименована в 'Rating').
# **Особенности:** Сильная несбалансированность классов.

FILE_PATH = '/kaggle/input/recipe-reviews-and-user-feedback-dataset/Recipe Reviews and User Feedback Dataset.csv'

# Чтение и первичная обработка
df = pd.read_csv(FILE_PATH)
df = df.rename(columns={'stars': 'Rating'})
df_clean = df.copy() 
print(f"Данные загружены. Размер датасета: {df.shape}")

display(df.head())
df.info()

# ---
# # 4. Обработка пропущенных значений (0.01%)

# Анализ пропусков
missing_data = df_clean.isnull().sum()[df_clean.isnull().sum() > 0]
if not missing_data.empty:
    print("\nОбнаружены пропущенные значения:")
    display(missing_data)
    
    # Пропуски только в текстовом поле 'text'. Удаляем строки.
    df_clean = df_clean.dropna(subset=['text'])
    print(f"\nПосле удаления пропусков (dropna): {df_clean.shape}")
else:
    print("\nПропущенные значения не обнаружены.")

# ---
# # 3. Визуализация данных и вычисление основных характеристик

numerical_features = ['user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score']

print(f"\nОсновные статистики для числовых признаков:")
display(df_clean[numerical_features].describe().T)

# Визуализация целевой переменной (Несбалансированность)
plt.figure(figsize=(8, 5))
sns.countplot(x='Rating', data=df_clean, palette='viridis')
plt.title('Распределение целевой переменной (Rating)')
plt.show()

# Расчет несбалансированности
rating_counts = df_clean['Rating'].value_counts(normalize=True).mul(100).round(2)
print("Процентное соотношение классов (несбалансированность):")
display(rating_counts.to_frame('Процент'))

# Корреляционная матрица
plt.figure(figsize=(10, 8))
sns.heatmap(df_clean[numerical_features + ['Rating']].corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Корреляционная матрица')
plt.show()
print("\nИнтерпретация: 'best_score' (R=0.50) и 'thumbs_up' (R=0.33) имеют наиболее заметную связь с целевой переменной. Высокая мультиколлинеарность отсутствует.")

# ---
# # 2. Разбить данные на обучающую и тестовую выборки

# Исключаем неинформативные признаки (ID, коды, текст)
X = df_clean.drop(['Rating', 'recipe_number', 'created_at', 'recipe_code', 'comment_id', 'user_id', 'user_name', 'text'], axis=1)
y = df_clean['Rating']

# Разделение 80/20 со стратификацией
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Размер обучающей выборки: {X_train.shape}")
print(f"Размер тестовой выборки: {X_test.shape}")

# ---
# # 5. Обработать категориальные признаки и # 6. Провести нормализацию

# Определяем признаки
categorical_features = ['recipe_name'] 
numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()

# Создаем препроцессор (ColumnTransformer)
preprocessor = ColumnTransformer(
    transformers=[
        # 6. Нормализация: StandardScaler необходим для KNN, так как этот метод чувствителен к масштабу признаков.
        ('num', StandardScaler(), numerical_features),
        # 5. Кодирование: OneHotEncoder для номинального категориального признака.
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='drop'
)
print("Препроцессор (StandardScaler + OneHotEncoder) настроен.")

# ---
# # 7. Запустить классификатор (KNeighborsClassifier)
# **Аргументация выбора:** KNN выбран для демонстрации необходимости нормализации данных (пункт 6) и подбора гиперпараметра (пункт 8).

# Создание и обучение базового пайплайна KNN
knn_base = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', KNeighborsClassifier(n_neighbors=5))
])

knn_base.fit(X_train, y_train)

# ---
# # 8. Вычислить ошибки, матрицы рассогласования и выбрать оптимальный k

# 8a. Оценка базовой модели (k=5)
y_train_pred_base = knn_base.predict(X_train)
y_test_pred_base = knn_base.predict(X_test)

print("\n=== Оценка базовой модели (KNN, k=5) ===")
print(f"Точность на ОБУЧАЮЩЕЙ выборке: {accuracy_score(y_train, y_train_pred_base):.4f}")
print(f"Точность на ТЕСТОВОЙ выборке:  {accuracy_score(y_test, y_test_pred_base):.4f}")

# 8b. Подбор оптимального k с использованием GridSearchCV

print("\n=== Выбор оптимального гиперпараметра k (GridSearchCV) ===")

# Определяем сетку гиперпараметров
param_grid = {'classifier__n_neighbors': np.arange(1, 21, 2)} 
cv_strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid_search = GridSearchCV(knn_base, param_grid, cv=cv_strat, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

best_k = grid_search.best_params_['classifier__n_neighbors']
print(f"\nОптимальное значение k: {best_k}")

# Оценка оптимальной модели
knn_best = grid_search.best_estimator_
y_test_pred_best = knn_best.predict(X_test)

print(f"\nТочность на ТЕСТОВОЙ выборке (Оптимальный k={best_k}): {accuracy_score(y_test, y_test_pred_best):.4f}")
print("Отчет по классификации (TEST, Оптимальный k):\n", classification_report(y_test, y_test_pred_best))


# ---
# # Визуализация: Матрица рассогласования (Пункт 8)

def plot_confusion_matrix(y_true, y_pred, model_name):
    """Строит визуализацию матрицы рассогласования."""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
    plt.title(f'Матрица рассогласования ({model_name})')
    plt.xlabel('Предсказанный класс')
    plt.ylabel('Фактический класс')
    plt.show()

print("\n=== Визуализация матрицы рассогласования (KNN) ===")
# Визуализация для лучшего KNN
plot_confusion_matrix(y_test, y_test_pred_best, f'KNN (k={best_k})')


# ---
# # 12. Общие выводы

# Сбор метрик для создания сводной таблицы
def get_metrics(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred, output_dict=True)
    return {
        'Модель': model_name,
        'Accuracy': accuracy_score(y_true, y_pred),
        'F1-Score (Wght Avg)': report['weighted avg']['f1-score'],
    }

# Получение метрик
metrics_knn = get_metrics(y_test, y_test_pred_best, f'KNN (k={best_k})')

# Создание итогового DataFrame
summary_df = pd.DataFrame([metrics_knn]).set_index('Модель')

print("\n\n# 12. Общие выводы")
print("--------------------")
print("1. Задача предсказания рейтинга ('stars') является задачей **мультиклассовой классификации**.")
print("2. Датасет сильно **несбалансирован** (класс '5' доминирует, ~76%).")
print("3. **Обработка данных** включала OHE для 'recipe_name' и **StandardScaler** (нормализация).")
print(f"4. **Оптимальный k** для KNN был найден с помощью GridSearchCV (k={best_k}).")

print("\n5. **Сводная таблица метрик (KNN на тестовой выборке):**")
display(summary_df.round(4))

print("\n6. **Вывод:**")
print(f"   - **KNN (k={best_k})** достиг общей точности {accuracy_score(y_test, y_test_pred_best):.4f} на тестовой выборке.")
print("   - Модель демонстрирует высокую точность на доминирующем классе ('5'), но слабее работает с редкими классами из-за дисбаланса.")